core:
  dags_folder: ~/airflow/dags
  executor: LocalExecutor
  sql_alchemy_conn: sqlite:////home/airflow/airflow.db
  load_examples: false

webserver:
  base_url: http://localhost:8080
  web_server_port: 8080
  web_server_host: 0.0.0.0
  secret_key: openlineage_secret_key
  workers: 2
  worker_class: sync

scheduler:
  job_heartbeat_sec: 5
  scheduler_heartbeat_sec: 5
  min_file_process_interval: 30
  dag_file_processor_timeout: 50
  max_tis_per_query: 512
  parallelism: 4

openlineage:
  transport: http
  url: http://localhost:5000
  namespace: example_namespace
  extractors:
    - airflow.DAG
    - airflow.TaskInstance
  protocol: http
  api_key: ""

logging:
  logging_level: INFO
  fab_logging_level: WARN
  log_filename_template: "{{ ti.dag_id }}/{{ ti.task_id }}/{{ ts }}/{{ try_number }}.log"
  log_processor_filename_template: "{{ filename }}.log"
  
email:
  email_backend: airflow.utils.email.send_email_smtp

smtp:
  smtp_host: localhost
  smtp_starttls: true
  smtp_ssl: false
  smtp_port: 25
  smtp_mail_from: airflow@example.com
